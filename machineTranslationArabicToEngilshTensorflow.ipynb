{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machineTranslationArabicToEngilshTensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFTEifS6G/O1ihruQCypUe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE4yckRQ2oBj"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import unicodedata\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import io\r\n",
        "import time"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIdpqjLdVjoL"
      },
      "source": [
        "# 1. Remove the accents\r\n",
        "# 2. Clean the sentences\r\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\r\n",
        "path_to_file = 'ara.txt'\r\n",
        "def create_dataset(path, num_examples):\r\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\r\n",
        "\r\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\r\n",
        "\r\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N7w9nKu5KIE"
      },
      "source": [
        "# now we will convert the data from unicode to ascii\r\n",
        "def unicode_to_ascii(s):\r\n",
        "  # this line of code convert each unistr to and remove the accent \r\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\r\n",
        "  # return all this exept the nonspacing mark\r\n",
        "      if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcr8VhjL2BUS"
      },
      "source": [
        "# now we will create a function to process or sentence\r\n",
        "def preprocess_sentence(w):\r\n",
        "  # first thing we will convert the unicode to ascii\r\n",
        "  w = unicode_to_ascii(w.lower().strip())\r\n",
        "\r\n",
        "  # creating a space between a word and the punctuation following it\r\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\r\n",
        "  w = re.sub(r\"([?؟.!,¿])\", r\" \\1 \", w)\r\n",
        "\r\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\r\n",
        "\r\n",
        "  w = w.strip()\r\n",
        "\r\n",
        "  # adding a start and an end token to the sentence\r\n",
        "  # so that the model know when to start and stop predicting.\r\n",
        "  w = '<start> ' + w + ' <end>'\r\n",
        "  return w\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0lqRtBVsCy",
        "outputId": "303cebbe-13b8-4d98-c864-1d02d0ef0b58"
      },
      "source": [
        "en, ara, shit = create_dataset(path_to_file,None)\r\n",
        "print(ara[1000])\r\n",
        "print(en[1000])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> ايمكنني مساعدتك ؟ <end>\n",
            "<start> may i help you ? <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPLcZf-W6oRo"
      },
      "source": [
        "# now let's do tokens to our text \r\n",
        "def tokenize(lang):\r\n",
        "  # here i make the fillter empty because i already process the data\r\n",
        "  lang_tok = tf.keras.preprocessing.text.Tokenizer(filters='')\r\n",
        "  # now let's do fit text to create an index for each word\r\n",
        "  lang_tok.fit_on_texts(lang)\r\n",
        "\r\n",
        "  # now let's make make every word alone\r\n",
        "  tensor = lang_tok.texts_to_sequences(lang)\r\n",
        "\r\n",
        "  # let's make pad seq to make all data has the same lenght\r\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\r\n",
        "\r\n",
        "  return tensor , lang_tok"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYgbb6m76-We"
      },
      "source": [
        "# now let's create a function to load the data set \r\n",
        "# and this function also tokenize the data also\r\n",
        "def load_dataset(path, num_examples=None):\r\n",
        "  # creating cleaned input, output pairs\r\n",
        "  targ_lang, inp_lang,shit_lang = create_dataset(path, num_examples)\r\n",
        "\r\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\r\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\r\n",
        "\r\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En-58zv67lOx"
      },
      "source": [
        "# now let's laod the data\r\n",
        "# here i will take part of the data to see what's going on and after this i will take all the data\r\n",
        "# here i take only 90000 line for the speed beacuse if i take all the data i take like a day to train\r\n",
        "num_examples = 90000\r\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file,num_examples)\r\n",
        "\r\n",
        "# now we can spilt the data into train and test\r\n",
        "# Creating training and validation sets using an 80-20 split\r\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\r\n",
        "# Calculate max_length of the target tensors\r\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bekn6axW8Oun",
        "outputId": "87395b3e-8a88-46cb-caa6-5e76e85595e2"
      },
      "source": [
        "# Show length\r\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9334 9334 2334 2334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDTmH3188651"
      },
      "source": [
        "# now we can create a function to show us the word and the index of this word\r\n",
        "def convert(lang, tensor):\r\n",
        "  for t in tensor:\r\n",
        "    if t !=0:\r\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31S2Dl8Y87yM",
        "outputId": "99869e93-6b2b-4a77-b170-95379519768e"
      },
      "source": [
        "# now let's use the function\r\n",
        "print (\"Input Language; index to word mapping\")\r\n",
        "convert(inp_lang, input_tensor_train[-1])\r\n",
        "print ()\r\n",
        "print (\"Target Language; index to word mapping\")\r\n",
        "convert(targ_lang, target_tensor_train[-1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "101 ----> اني\n",
            "492 ----> ابحث\n",
            "23 ----> عن\n",
            "374 ----> كتاب\n",
            "23 ----> عن\n",
            "1597 ----> اسبانيا\n",
            "9 ----> في\n",
            "4183 ----> العصور\n",
            "4184 ----> الوسطى\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "29 ----> i'm\n",
            "186 ----> looking\n",
            "30 ----> for\n",
            "9 ----> a\n",
            "87 ----> book\n",
            "60 ----> about\n",
            "2435 ----> medieval\n",
            "1296 ----> spain\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_fJOo399GW8",
        "outputId": "980df27a-ad16-496a-9043-d928f68f4bbc"
      },
      "source": [
        "# now we will create the tf.data.dataset\r\n",
        "BUFFER_SIZE = len(input_tensor_train)\r\n",
        "BATCH_SIZE = 64\r\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\r\n",
        "embedding_dim = 256\r\n",
        "units = 1024\r\n",
        "vocab_inp_size = len(inp_lang.word_index)+ 1\r\n",
        "vocab_tar_size = len(targ_lang.word_index)+ 1\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\r\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\r\n",
        "dataset"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 39), (64, 39)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jOHcXzP9d7d",
        "outputId": "0c8d09ad-9fd6-4f2e-a235-bbf63cf4e435"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\r\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 39]), TensorShape([64, 39]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PeVK8lU9hEI"
      },
      "source": [
        "class Encoder(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.enc_units = enc_units\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "  # this layer in the encoder give us the output from the embedding layer,\r\n",
        "  #  and pass this to the next layer GRU and this layer give us the new state and the output\r\n",
        "  def call(self, x, hidden):\r\n",
        "    x = self.embedding(x)\r\n",
        "    output, state = self.gru(x, initial_state = hidden)\r\n",
        "    return output, state\r\n",
        "  \r\n",
        "  # this function initialize a zeros numbers to initialize the state for frist time or for test shit\r\n",
        "  def initialize_hidden_state(self):\r\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0f9Koh_AfTp",
        "outputId": "503ed0d3-c618-45c0-d1d6-6697b3036374"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "# sample input\r\n",
        "sample_hidden = encoder.initialize_hidden_state()\r\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\r\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\r\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 39, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xr2z5r_BjlQ"
      },
      "source": [
        "# now we will create the attention layer \r\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\r\n",
        "  def __init__(self, units):\r\n",
        "    super(BahdanauAttention, self).__init__()\r\n",
        "    self.W1 = tf.keras.layers.Dense(units)\r\n",
        "    self.W2 = tf.keras.layers.Dense(units)\r\n",
        "    self.V = tf.keras.layers.Dense(1)\r\n",
        "\r\n",
        "  def call(self, query, values):\r\n",
        "    # query hidden state shape == (batch_size, hidden size)\r\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\r\n",
        "    # values shape == (batch_size, max_len, hidden size)\r\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\r\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\r\n",
        "    # score shape == (batch_size, max_length, 1)\r\n",
        "    # we get 1 at the last axis because we are applying score to self.V\r\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\r\n",
        "    score = self.V(tf.nn.tanh(\r\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\r\n",
        "    \r\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\r\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\r\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\r\n",
        "    context_vector = attention_weights * values\r\n",
        "\r\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\r\n",
        "\r\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY0QYRlsDyKG",
        "outputId": "2e356800-9bf1-4974-f21c-5513e61ff0e2"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\r\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\r\n",
        "\r\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\r\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 39, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhflzJ84EGTM"
      },
      "source": [
        "# now we will create the decoder\r\n",
        "class Decoder(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "    self.batch_sz = batch_sz\r\n",
        "    self.dec_units = dec_units\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True,\r\n",
        "                                   recurrent_initializer='glorot_uniform')\r\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    # used for attention\r\n",
        "    self.attention = BahdanauAttention(self.dec_units)\r\n",
        "\r\n",
        "  def call(self, x, hidden, enc_output):\r\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\r\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\r\n",
        "\r\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n",
        "    x = self.embedding(x)\r\n",
        "\r\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n",
        "\r\n",
        "    # passing the concatenated vector to the GRU\r\n",
        "    output, state = self.gru(x)\r\n",
        "\r\n",
        "    # output shape == (batch_size * 1, hidden_size)\r\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\r\n",
        "\r\n",
        "    # output shape == (batch_size, vocab)\r\n",
        "    x = self.fc(output)\r\n",
        "\r\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk3mQhpUySzE",
        "outputId": "fc52d0d0-50e1-40b8-817a-4227a9a35cd4"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\r\n",
        "                                      sample_hidden, sample_output)\r\n",
        "\r\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4292)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz2HG3HAylSG"
      },
      "source": [
        "# now we will make the ope and the loss function\r\n",
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "    from_logits=True, reduction='none')\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n",
        "  loss_ = loss_object(real, pred)\r\n",
        "\r\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\r\n",
        "  loss_ *= mask\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPQh27ZnyuiE"
      },
      "source": [
        "# now we will create the check point \r\n",
        "checkpoint_dir = 'training_checkpoints'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGfawf8dy2ma"
      },
      "source": [
        "# now we will train our model\r\n",
        "@tf.function\r\n",
        "def train_step(inp, targ, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n",
        "\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "\r\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\r\n",
        "\r\n",
        "    # Teacher forcing - feeding the target as the next input\r\n",
        "    for t in range(1, targ.shape[1]):\r\n",
        "      # passing enc_output to the decoder\r\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n",
        "\r\n",
        "      loss += loss_function(targ[:, t], predictions)\r\n",
        "\r\n",
        "      # using teacher forcing\r\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\r\n",
        "\r\n",
        "  batch_loss = (loss / int(targ.shape[1]))\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "\r\n",
        "  gradients = tape.gradient(loss, variables)\r\n",
        "\r\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\r\n",
        "\r\n",
        "  return batch_loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvDA3mofzltp",
        "outputId": "8bf304ea-18f0-44e5-c9fa-cb3f6115a82a"
      },
      "source": [
        "EPOCHS = 10\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start = time.time()\r\n",
        "\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\r\n",
        "    total_loss += batch_loss\r\n",
        "\r\n",
        "    if batch % 100 == 0:\r\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                                   batch,\r\n",
        "                                                   batch_loss.numpy()))\r\n",
        "  # saving (checkpoint) the model every 2 epochs\r\n",
        "  if (epoch + 1) % 2 == 0:\r\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                      total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.6453\n",
            "Epoch 1 Batch 100 Loss 0.9118\n",
            "Epoch 1 Loss 1.0260\n",
            "Time taken for 1 epoch 163.1452271938324 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9154\n",
            "Epoch 2 Batch 100 Loss 0.7937\n",
            "Epoch 2 Loss 0.8405\n",
            "Time taken for 1 epoch 112.87377738952637 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.7444\n",
            "Epoch 3 Batch 100 Loss 0.7868\n",
            "Epoch 3 Loss 0.7549\n",
            "Time taken for 1 epoch 111.82068514823914 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7081\n",
            "Epoch 4 Batch 100 Loss 0.6542\n",
            "Epoch 4 Loss 0.6897\n",
            "Time taken for 1 epoch 112.56700015068054 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.6051\n",
            "Epoch 5 Batch 100 Loss 0.6332\n",
            "Epoch 5 Loss 0.6327\n",
            "Time taken for 1 epoch 112.88552045822144 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.5777\n",
            "Epoch 6 Batch 100 Loss 0.5974\n",
            "Epoch 6 Loss 0.5723\n",
            "Time taken for 1 epoch 113.05138945579529 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.5148\n",
            "Epoch 7 Batch 100 Loss 0.5154\n",
            "Epoch 7 Loss 0.5098\n",
            "Time taken for 1 epoch 112.49006652832031 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.4717\n",
            "Epoch 8 Batch 100 Loss 0.5160\n",
            "Epoch 8 Loss 0.4453\n",
            "Time taken for 1 epoch 113.3359022140503 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.3827\n",
            "Epoch 9 Batch 100 Loss 0.4096\n",
            "Epoch 9 Loss 0.3780\n",
            "Time taken for 1 epoch 112.97763133049011 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.2894\n",
            "Epoch 10 Batch 100 Loss 0.3146\n",
            "Epoch 10 Loss 0.3123\n",
            "Time taken for 1 epoch 112.07223582267761 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZUhaH1sz-Zx"
      },
      "source": [
        "# here is the step for the evalution step\r\n",
        "# The evaluate function is similar to the training loop, except we don't use teacher forcing here.\r\n",
        "# The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\r\n",
        "# Stop predicting when the model predicts the end token.\r\n",
        "# And store the attention weights for every time step.\r\n",
        "def evaluate(sentence):\r\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\r\n",
        "\r\n",
        "  sentence = preprocess_sentence(sentence)\r\n",
        "\r\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                         maxlen=max_length_inp,\r\n",
        "                                                         padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "\r\n",
        "  result = ''\r\n",
        "\r\n",
        "  hidden = [tf.zeros((1, units))]\r\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "\r\n",
        "  dec_hidden = enc_hidden\r\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\r\n",
        "\r\n",
        "  for t in range(max_length_targ):\r\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "\r\n",
        "    # storing the attention weights to plot later on\r\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "    attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "\r\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\r\n",
        "\r\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\r\n",
        "      return result, sentence, attention_plot\r\n",
        "\r\n",
        "    # the predicted ID is fed back into the model\r\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af-62Vxv0D0Z"
      },
      "source": [
        "# function for plotting the attention weights\r\n",
        "def plot_attention(attention, sentence, predicted_sentence):\r\n",
        "  fig = plt.figure(figsize=(10,10))\r\n",
        "  ax = fig.add_subplot(1, 1, 1)\r\n",
        "  ax.matshow(attention, cmap='viridis')\r\n",
        "\r\n",
        "  fontdict = {'fontsize': 14}\r\n",
        "\r\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\r\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\r\n",
        "\r\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVaubVFr0GOA"
      },
      "source": [
        "# this is the translate function\r\n",
        "def translate(sentence):\r\n",
        "  result, sentence, attention_plot = evaluate(sentence)\r\n",
        "\r\n",
        "  print('Input: %s' % (sentence))\r\n",
        "  print('Predicted translation: {}'.format(result))\r\n",
        "\r\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\r\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_qRkXXt0JoU",
        "outputId": "868eeb22-acf5-4cba-936a-335413842de8"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcc3dfe3358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "M_RNeh-i0L4d",
        "outputId": "c085500f-afe3-409d-a5cf-138a4b5cc5f0"
      },
      "source": [
        "# and now let's see the translation\r\n",
        "translate(u' انا اكره مصر ')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> انا اكره مصر <end>\n",
            "Predicted translation: i hate egypt . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}